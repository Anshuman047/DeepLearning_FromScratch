{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68886fa3-48a7-457e-bff3-a153f171d27c",
   "metadata": {},
   "source": [
    "# Forward Propagation with having no Hidden Layer, direct input layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae080ac-2fa9-45a7-acb9-0b051efa2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc649e7-c46d-4b01-903a-e1dbbd846daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ possible values as our input as AND operator\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50ac4bd-520e-4f77-8302-be67d98ff692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "[0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)\n",
    "Y.reshape(-1,1) # converted into 2D array(Matrix formate) as same as our X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb165a6-342c-4bb4-bdac-a33f12e36843",
   "metadata": {},
   "source": [
    "## Defining Sigmid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4066bf5-d2df-4807-ab34-bd220284ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the sigmoid function:\n",
    "def sig(z):\n",
    "    return (1/(1+np.exp(-z))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80637d-8397-41bd-9082-3bac3afd4397",
   "metadata": {},
   "source": [
    "## Defining the weights as per following the rules, no hidden layer weights, that is from input neuron to direct output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "082a1d6c-fa0a-496b-82fd-c8e4e0becda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.64724472],\n",
       "       [-0.60338515]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intilize random weights to start with forward propagation\n",
    "# From np.random module, a random function is there, which provides random number as given the shape parametrs, so we required 2 rows and 1 column, as from 2-input-neuron to 1-output-neuron -> (2,1)\n",
    "weights = 2*np.random.random((2,1))-1 #But it would give numbers in range of 0 to 1 , but we required -1 to 1, so we first multiply it with 2, so that range became 0 to 2, and then substracted by 1 so that range became -1 to 1\n",
    "print(weights.shape)\n",
    "weights # As we reuired ideal weights to be from -1 to 1 and should be in 2D. as co be equal to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08946dc-fe36-4a76-b65b-3b1391e29edb",
   "metadata": {},
   "source": [
    "## Defining the bias, as we required here only 1 bias, that is from inptu neuron to direct output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f794962e-033c-4fac-b5c2-4560f4fec82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66699023])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = 2 * np.random.random(1)-1 # Same concept as implimneted above, same -1 to 1\n",
    "# Shape inside passed (1), bias is bydefault 1, so bias connected to how many neuron passed here that is (1) \n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8437a7b3-bc88-44b2-bb16-277ad90d63da",
   "metadata": {},
   "source": [
    "## Constructing the network for forward propagation without any hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "970179eb-5f2d-4add-9129-0332e1098da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.66082889],\n",
       "       [0.61835401],\n",
       "       [0.54797069],\n",
       "       [0.50201305]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now input layer output is directly giving the output\n",
    "inputOut = X\n",
    "output = sig(np.dot(inputOut, weights)+ bias) #Vector multiplication / matrix multiplication of X and weights, 4x2 into 2x1 would give 4x1 and there summation with eachother as well as with bias will be passed to sigmoid function which gonna be our output \n",
    "# Here np.dot will multiply first datapoint with weights and summed summed with eachohter as well with bias also and call sigmoid function and return value to output same with next datapoints in X(inputOut), and saved them all in output which is a array/list \n",
    "print(type(output))\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
